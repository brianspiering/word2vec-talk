{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "word2vec\n",
    "----\n",
    "\n",
    "<img src=\"images/book.png\" style=\"width: 300px;\" align=\"middle\"/>\n",
    "\n",
    "Slides: [bit.ly/word2vec_talk](http://bit.ly/word2vec_talk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "Agenda\n",
    "----\n",
    "\n",
    "0) Welcome!    \n",
    "1) What is word2vec?  \n",
    "2) How does word2vec work?  \n",
    "3) What can you do with word2vec?   \n",
    "4) Demo(?)    \n",
    "\n",
    "Slides: [bit.ly/word2vec_talk](http://bit.ly/word2vec_talk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/me_cropped.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "hi, brian. [@BrianSpiering](https://twitter.com/brianspiering)\n",
    "\n",
    "Data Science Faculty @[GalvanizeU](http://www.galvanizeu.com/)\n",
    "\n",
    "Slides: [bit.ly/word2vec_talk](http://bit.ly/word2vec_talk)  \n",
    "(adapted from my Natural Language Processing (NLP) course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Pop Quiz\n",
    "---\n",
    "\n",
    "Do computers prefer numbers or words?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Numbers__\n",
    "<br>\n",
    "<br>\n",
    "word2vec is a series of algorithms to map words (strings) to numbers (lists of floats).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/tsne.png\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "output = {'fox': [-0.00449447, -0.00310097]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00449447, -0.00310097]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The quick brown fox\"\n",
    "\n",
    "print(output['fox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why is word2vec so popular?\n",
    "----\n",
    "\n",
    "1. Creates a word \"cloud\", organized by semantic meaning.\n",
    "\n",
    "2. Converts text into a numerical form that machine learning algorithms and Deep Learning Neural Nets can then use as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "<img src=\"images/firth.png\" style=\"width: 300px;\"/>\n",
    "\n",
    ">“You shall know a word\n",
    ">by the company it keeps”\n",
    "\n",
    "> \\- J. R. Firth 1957\n",
    "\n",
    "__Distributional Hypothesis__: Words that occur in the same contexts tend to have similar meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example:__  \n",
    "> ... government debt problems are turning into __banking__ crises...  \n",
    "\n",
    "> ... Europe governments needs unified __banking__ regulation to replace the hodgepodge of debt regulations...\n",
    "\n",
    "The words: _government_, _regulation_, and _debt_ probably represent some aspect of _banking_ since they frequently appear near by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does word2vec model the Distributional Hypothesis?\n",
    "---\n",
    "\n",
    "word2Vec is a very simple neural network:\n",
    "<img src=\"images/w2v_neural_net.png\" style=\"width: 350px;\"/>\n",
    "\n",
    "[Source](http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Skip-gram architecture\n",
    "----\n",
    "\n",
    "<img src=\"images/skip-gram.png\" style=\"width: 300px;\"/>\n",
    "Given the current word, predict the context (surrounding words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Skip-gram example\n",
    "---\n",
    "\n",
    ">“Insurgents killed in ongoing fighting”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bigrams = [\"insurgents killed\", \"killed in\", \"in ongoing\", \"ongoing fighting\"]\n",
    "\n",
    "skip_2_bigrams = [\"insurgents killed\", \"insurgents in\", \"insurgents ongoing\", \"killed in\", \n",
    "                  \"killed ongoing\", \"killed fighting\", \"in ongoing\", \"in fighting\", \"ongoing fighting\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have word vectors, what can we do?\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Math with words!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/math.jpg\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Types of Word Math\n",
    "----\n",
    "\n",
    "1. Distance\n",
    "2. Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Distance\n",
    "---\n",
    "<br>\n",
    "<img src=\"images/family.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "Words that are related will be closer than unrelated words, thus the relationships between words can encoded as distance through the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/cosine.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words closest to “Sweden”\n",
    "----\n",
    "\n",
    "<img src=\"images/sweden_cosine_distance.png\" style=\"width: 300px;\"/>\n",
    " \n",
    "[Source](http://deeplearning4j.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Arithmetic: Word analogies\n",
    "---\n",
    "\n",
    "![](http://multithreaded.stitchfix.com/assets/images/blog/vectors.gif)\n",
    "\n",
    "The \"Hello, world!\" of word2vec:\n",
    "> Man is to woman as king is to queen\n",
    "\n",
    "$cos(w, king) - cos(w, man) + cos(w, woman) = cos(w, queen)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Verb Tense\n",
    "----\n",
    "\n",
    "<img src=\"images/verb.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "everything2vec\n",
    "----\n",
    "\n",
    "<img src=\"images/all_the_things.jpg\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/emjois.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "emjoi2vec\n",
    "----\n",
    "<img src=\"https://s3.amazonaws.com/instagram-static/engineering-blog/emoji-hashtags/tsne_map_tight.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "[Source](http://instagram-engineering.tumblr.com/post/117889701472/emojineering-part-1-machine-learning-for-emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "----\n",
    "\n",
    "- word2vec: Create a dense vector representation of words that models semantic meaning based on context\n",
    "- Then you can do math with words\n",
    "- Sets you up for machine learning and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Where do I go from here?\n",
    "-----\n",
    "\n",
    "- Download these slides: [bit.ly/word2vec_talk](http://bit.ly/word2vec_talk) \n",
    "- Check out my [word2vec workshop](https://github.com/brianspiering/word2vec-workshop)\n",
    "- Watch Ali Ghodsi's lecture on word2vec [part 1](https://www.youtube.com/watch?v=TsEGsdVJjuA) and [part 2](https://www.youtube.com/watch?v=nuirUEmbaJU)\n",
    "- Work through [Tensorflow's word2vec tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/word2vec/index.html)\n",
    "- Neural Networks Demystified:\n",
    "    + [Watch](https://www.youtube.com/watch?v=5MXp9UUkSmc) \n",
    "    + [Code](http://nbviewer.ipython.org/github/stephencwelch/Neural-Networks-Demysitifed/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/anyquestions.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
